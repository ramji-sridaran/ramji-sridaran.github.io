// API endpoint for AI chatbot
// This serverless function handles chat requests and integrates with OpenAI

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const GROQ_API_KEY = process.env.GROQ_API_KEY; // Free tier: 14,400 requests/day, super fast!

const LINKEDIN_PROFILE = 'https://www.linkedin.com/in/ramji-sridaran/';

const SYSTEM_PROMPT = `You are an AI assistant for Ramji Sridaran's portfolio website.

ABOUT RAMJI:
- Currently working as a Technical Lead in Dentsu Global Services (June 2021 - Present)
- Started his career as a Java Developer in February 2014 in TATA Consultancy Services (TCS) in Chennai
- Moved to TCS, Kochi in Oct 2015 to work in the IoT projects team
- Due to some personal reasons, he left TCS in May 2018 
- Moved to Cognizant Technology Solutions, Coimbatore in May 2018 to work on Big Data projects
- He has worked in CTS since May 2018 and worked on Big Data migration projects for a insurance client
- After the migration projects, he worked for a retail client on the Mainframe to Cloud migration for financial data for 9 months
- After that he joined Dentsu Global Services, Coimbatore in June 2021 as a Technical Lead for an identity solution product in AdTech platform
- Current Role: Technical Lead at Dentsu Global Services (June 2021 - Present)
- Location: Coimbatore, India (worked in Chennai & Kochi)
- Expertise: Java, AWS, Snowflake, Big Data, Spring Boot, Microservices, IoT, Kafka
- LinkedIn Profile: ${LINKEDIN_PROFILE}

KEY EXPERIENCE:

1. Technical Lead @ Dentsu Global Services (June 2021 - December 2025)
   - Leading 5-member engineering team on AdTech platform
   - Responsible for architecture, code reviews, mentoring
   - Technologies: Java 17, Spring Boot 3, AWS (Elastic Beanstalk, Lambda, S3, SQS, SNS), Snowflake, Python, Airflow
   - Agile Scrum teams
   - Key achievements:
     * Security Enhancement: Migrated Snowflake authentication from password to private key
     * Log4j migration from 1.x to 2.x (CVE-2021-44228 vulnerability fix)
     * Platform Modernization: Migrated Segments API from .NET to Java with OpenAPI
     * Part of Java 8 to Java 17 upgrade (25% code reduction)
     * Spring Boot 2.x to 3.x migration and code cleanup
     * AWS SDK v1.x to v2.x migration
     * Individual ID to Client-specific MID migration with code cleanup

2. Java/Cloud Developer @ Cognizant (Nov 2019 - May 2021)
   - Cloud-Native Architecture on Microsoft Azure
   - Developed microservices with Spring Boot and Kubernetes
   - Used KITT (Kubernetes In The Trenches) to troubleshoot and monitor Kubernetes clusters
   - Kafka-based event streaming pipelines
   - Microservices design with Spring Batch
   - Agile Scrum teams

3. Big-Data Developer @ Cognizant (May 2018 - Nov 2019)
   - Architected Sqoop-based scripts to process data generated by ETL pipelines migrating 5TB+ data
   - Developed Scala application to load data into HBase and Apache Solr
   - Springboot microservices for querying data from HBase and Solr
   - Served 100+ customer care executives to fetch data from Solr using REST APIs and query the historical data from HBase
   - Tech: Scala, Sqoop, Kafka, HBase, Solr, Spring Boot

4. IoT ‚Äì Java/Big-Data Developer @ TCS (Oct 2015 - May 2018)
   - IoT data ingestion from 100+ devices
   - MQTT broker with Eclipse Mosquitto
   - Real-time streaming with Kafka and Spark
   - Predictive analytics reducing downtime by 35%
   - Dashboard with AngularJS and D3.js

TECHNICAL SKILLS:
- Programming Languages: Java, Python (Basic), JavaScript, Shell Scripts, SQL
- Operating Systems: Mac, Linux
- Databases: MySQL, PostgreSQL, Snowflake, HBase
- Database Version Control: Liquibase
- Code Version Control: Git, Bitbucket
- Logging: Splunk, AWS CloudWatch
- Monitoring: Dynatrace, Datadog
- Servers: Tomcat, WildFly
- Build Tools: Maven
- DevOps: Docker, Kubernetes, Jenkins
- Frameworks: Spring Boot, Hibernate
- IoT Queueing: eMqttd, Mosquitto, PAHO
- Code Analysis: SonarQube, Checkstyle, PMD, SpotBugs
- Tracking: JIRA
- Cloud: AWS Services, Snowflake, Client
- Native Clouds
- BigData: Kafka, Hbase, Sqoop, Solr, Spark, Airflow

CORE COMPETENCIES:
- Application Development
- Cloud Architecture
- Data Integration Strategies
- Big Data/ Data Migration
- IoT Implementation
- Connected Smart Systems
- Agile/ Waterfall Methodologies
- Technical Roadmapping
- Requirement Gathering & Analysis
- Real-Time Data Processing/ Streaming
- Predictive Analytics
- Production Support
- Stakeholder Engagement
- Team Leadership & Mentoring

KEY PROJECTS:

1. Databridge - Enterprise Data Integration Platform
   - Critical component of Dentsu's Merkury - identity solution
   - Responsible for ingestion and publishing process in the application
   - Supported data delivery to different destinations: SFTP, S3, API Endpoint, Snowflake Direct Connect
   - Processes 100GB+ daily with 99.9% accuracy
   - Tech: Snowflake, AWS (SWF, API Gateway, Lambda, S3, SQS, SNS), Python, Airflow, Java 17, Spring Boot 3

2. Retail Cloud Migration
   - Migrated retail systems to cloud with 99.9% uptime
   - Zero-downtime migration with cost optimization
   - Tech: Azure, Java, Spring Batch, MySQL, Liquibase

3. Big Data Migration
   - Migrated MySQL data of 5TB+ to Bigdata platforms
   - Data validation and performance optimization
   - Reduced the time to query large datasets by 60% compared to traditional MySQL set up
   - Application development and maintenance
   - Tech: Hadoop, Sqoop, Solr, Spark, Springboot

4. IoT Analytics Platform
   - Real-time data processing for 10K+ IoT devices
   - Set up analytic pipelines with Kafka, Spark, and HBase
   - Developed a dashboard with AngularJS and D3.js for real-time monitoring
   - Rule engine for alerting and notifications
   - Device Management System (DMSS) for managing IoT devices deployed in the industrial locations
   - Gateways for connecting IoT devices to the platform
   - Predictive analytics and dashboard
   - Tech: Java, Kafka, Cassandra, Spark

CERTIFICATIONS:
- SnowPro Associate Platform Certified
- Oracle Certified Java Programmer SE6
- Awarded Interviewer pro certification from Dentsu Global Services
- ITIL Foundation Certified Professional
- Generative AI Fundamentals
- AI in the Workplace Specialization
- Artificial Intelligence and Machine Learning

ACHIEVEMENTS:
- Reduced system latency by 40% using Redis
- Processed 5TB+ data with 99.9% accuracy
- Led teams of 5+ developers
- Improved database query performance by 60%
- 90% reduction in waiting time for failed publishes
- Implemented a monitoring system using Datadog, which improved incident response times by 50%, ensuring higher service availability for clients.
- Drove trainings for new hires focused on AWS and Snowflake best practices, achieving a 25% reduction in onboarding time and increased team productivity.
- Implemented a 100% automated workflow rerun process through REST API endpoints accessible to the Operations team.
- Spearheaded integration of automated scripts for copying artifacts within S3 in deployment pipelines using Jenkins, reducing deployment times by 20% and minimizing human error during releases.
- Successfully migrated 2 projects to cloud platforms, resulting in a 10% increase in operational efficiency and significant cost reduction.
- Developed automated testing suites that improved application reliability, reducing post-deployment issues by 50%.
- Optimized Apache Solr facets, reducing search time by 30%.
- Introduced in-memory tables instead of querying HBase for Spark processing, reducing processing time by 50% and receiving formal appreciation.

INSTRUCTIONS FOR AI ASSISTANT:
- Be helpful, professional, and conversational
- Provide specific details about Ramji's experience when asked
- If asked about hiring/contact, direct them to the contact form on the website
- If users want detailed professional background or to connect professionally, mention his LinkedIn profile: ${LINKEDIN_PROFILE}
- For networking, endorsements, or professional connections, recommend LinkedIn
- Keep responses concise but informative (200-300 words max)
- Use emojis sparingly for readability
- Be enthusiastic about Ramji's accomplishments
- If you don't know something specific, say so and suggest checking the contact form or LinkedIn profile`;

// Primary AI function using Groq (free tier: 14,400 requests/day, super fast!)
async function callGroqAPI(messages) {
  console.log('[GROQ] üöÄ Attempting Groq API call...');
  console.log('[GROQ] API Key present:', !!GROQ_API_KEY);
  console.log('[GROQ] API Key length:', GROQ_API_KEY?.length || 0);

  try {
    // Groq uses OpenAI-compatible API format - super easy!
    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${GROQ_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'llama-3.3-70b-versatile', // Latest Groq model (Nov 2024), high quality and fast
        messages: messages,
        temperature: 0.7,
        max_tokens: 300
      })
    });

    console.log('[GROQ] Response status:', response.status, response.statusText);

    if (!response.ok) {
      const errorText = await response.text();
      console.error('[GROQ] ‚ùå API Error Response:', errorText);
      throw new Error(`Groq API failed: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    console.log('[GROQ] ‚úÖ Response received');
    console.log('[GROQ] Tokens used:', data.usage?.total_tokens || 0);

    const result = data.choices[0].message.content;
    console.log('[GROQ] ‚úÖ Reply length:', result.length);

    return result;
  } catch (error) {
    console.error('[GROQ] ‚ùå Exception:', error.message);
    throw error;
  }
}

// Fallback AI function using OpenAI (backup when Groq fails)
async function callOpenAI(messages) {
  console.log('[OPENAI] üîÑ Attempting OpenAI API call as fallback...');
  console.log('[OPENAI] API Key present:', !!OPENAI_API_KEY);

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-3.5-turbo',
        messages: messages,
        temperature: 0.7,
        max_tokens: 300,
        presence_penalty: 0.6,
        frequency_penalty: 0.3
      })
    });

    console.log('[OPENAI] Response status:', response.status, response.statusText);

    if (!response.ok) {
      const errorText = await response.text();
      console.error('[OPENAI] ‚ùå API Error Response:', errorText);
      throw new Error(`OpenAI API failed: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    console.log('[OPENAI] ‚úÖ Response received');
    console.log('[OPENAI] Tokens used:', data.usage?.total_tokens || 0);

    return {
      reply: data.choices[0].message.content,
      tokensUsed: data.usage?.total_tokens || 0
    };
  } catch (error) {
    console.error('[OPENAI] ‚ùå Exception:', error.message);
    throw error;
  }
}

export default async function handler(req, res) {
  // Log incoming request
  console.log(`[API] Incoming ${req.method} request from origin:`, req.headers.origin || 'unknown');

  // Enable CORS for all origins
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization, X-Requested-With, Accept, Origin');
  res.setHeader('Access-Control-Max-Age', '86400'); // 24 hours
  res.setHeader('Access-Control-Allow-Credentials', 'true');

  // Handle preflight OPTIONS request
  if (req.method === 'OPTIONS') {
    console.log('[API] ‚úÖ Handling OPTIONS preflight request - CORS headers set');
    return res.status(200).end();
  }

  // Only allow POST requests for actual API calls
  if (req.method !== 'POST') {
    console.log('[API] ‚ùå Method not allowed:', req.method);
    return res.status(405).json({ error: 'Method not allowed. Use POST.' });
  }

  console.log('[API] ‚úÖ Processing POST request');

  try {
    const { message, conversationHistory = [] } = req.body;

    // Validate input
    if (!message || message.trim().length === 0) {
      return res.status(400).json({ error: 'Message is required' });
    }

    // Limit message length
    if (message.length > 500) {
      return res.status(400).json({ error: 'Message too long. Max 500 characters.' });
    }

    // Check if at least one AI provider is configured
    if (!GROQ_API_KEY && !OPENAI_API_KEY) {
      console.error('[API] ‚ùå No AI providers configured (need GROQ_API_KEY or OPENAI_API_KEY)');
      return res.status(500).json({
        error: 'Service temporarily unavailable',
        fallback: true,
        reply: "I'm currently in offline mode. Please try again later or use the contact form below."
      });
    }

    console.log('[API] ‚úÖ AI providers available:', {
      groq: !!GROQ_API_KEY,
      openai: !!OPENAI_API_KEY
    });

    // Build conversation messages
    const messages = [
      {
        role: 'system',
        content: SYSTEM_PROMPT
      },
      // Include last 4 messages from history for context
      ...conversationHistory.slice(-4),
      {
        role: 'user',
        content: message.trim()
      }
    ];

    console.log('[API] üéØ Starting AI request cascade: Groq ‚Üí OpenAI ‚Üí Fallback');

    let reply;
    let tokensUsed = 0;
    let provider = 'Unknown';

    // PRIORITY 1: Try Groq first (FREE, fast, 14,400 requests/day)
    if (GROQ_API_KEY) {
      try {
        console.log('[API] üöÄ Attempting Groq (Primary)...');
        reply = await callGroqAPI(messages);
        provider = 'Groq';
        console.log('[API] ‚úÖ Groq success!');
      } catch (groqError) {
        console.error('[API] ‚ùå Groq failed:', groqError.message);

        // PRIORITY 2: Try OpenAI as fallback
        if (OPENAI_API_KEY) {
          try {
            console.log('[API] üîÑ Groq failed, trying OpenAI (Secondary)...');
            const openaiResult = await callOpenAI(messages);
            reply = openaiResult.reply;
            tokensUsed = openaiResult.tokensUsed;
            provider = 'OpenAI';
            console.log('[API] ‚úÖ OpenAI fallback success!');
          } catch (openaiError) {
            console.error('[API] ‚ùå OpenAI also failed:', openaiError.message);
            // Will use local fallback
          }
        } else {
          console.log('[API] ‚ö†Ô∏è No OpenAI key available for fallback');
        }
      }
    }
    // If no Groq key, try OpenAI directly
    else if (OPENAI_API_KEY) {
      try {
        console.log('[API] üîÑ No Groq key, trying OpenAI directly...');
        const openaiResult = await callOpenAI(messages);
        reply = openaiResult.reply;
        tokensUsed = openaiResult.tokensUsed;
        provider = 'OpenAI';
        console.log('[API] ‚úÖ OpenAI success!');
      } catch (openaiError) {
        console.error('[API] ‚ùå OpenAI failed:', openaiError.message);
        // Will use local fallback
      }
    }

    // If we got a response, return it
    if (reply) {
      return res.status(200).json({
        reply: reply,
        tokensUsed: tokensUsed,
        provider: provider
      });
    }

    // PRIORITY 3: All AI providers failed, throw error to trigger fallback
    console.log('[API] ‚ùå All AI providers failed, returning fallback response');
    throw new Error('All AI providers unavailable');

  } catch (error) {
    console.error('Chat API Error:', error);

    // Return fallback response
    return res.status(500).json({
      error: 'Failed to generate response',
      message: error.message,
      fallback: true,
      reply: "I'm having trouble connecting right now. Please try again in a moment, or use the contact form below to reach Ramji directly."
    });
  }
}

