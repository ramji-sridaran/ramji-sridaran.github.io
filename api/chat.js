// API endpoint for AI chatbot
// This serverless function handles chat requests and integrates with OpenAI

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const HUGGINGFACE_API_KEY = process.env.HUGGINGFACE_API_KEY; // Free tier available

const LINKEDIN_PROFILE = 'https://www.linkedin.com/in/ramji-sridaran/';

const SYSTEM_PROMPT = `You are an AI assistant for Ramji Sridaran's portfolio website.

ABOUT RAMJI:
- Currently working as a Technical Lead in Dentsu Global Services (June 2021 - Present)
- Started his career as a Java Developer in February 2014 in TATA Consultancy Services (TCS) in Chennai
- Moved to TCS, Kochi in Oct 2015 to work in the IoT projects team
- Due to some personal reasons, he left TCS in May 2018 
- Moved to Cognizant Technology Solutions, Coimbatore in May 2018 to work on Big Data projects
- He has worked in CTS since May 2018 and worked on Big Data migration projects for a insurance client
- After the migration projects, he worked for a retail client on the Mainframe to Cloud migration for financial data for 9 months
- After that he joined Dentsu Global Services, Coimbatore in June 2021 as a Technical Lead for an identity solution product in AdTech platform
- Current Role: Technical Lead at Dentsu Global Services (June 2021 - Present)
- Location: Coimbatore, India (worked in Chennai & Kochi)
- Expertise: Java, AWS, Snowflake, Big Data, Spring Boot, Microservices, IoT, Kafka
- LinkedIn Profile: ${LINKEDIN_PROFILE}

KEY EXPERIENCE:

1. Technical Lead @ Dentsu Global Services (June 2021 - December 2025)
   - Leading 5-member engineering team on AdTech platform
   - Responsible for architecture, code reviews, mentoring
   - Technologies: Java 17, Spring Boot 3, AWS (Elastic Beanstalk, Lambda, S3, SQS, SNS), Snowflake, Python, Airflow
   - Agile Scrum teams
   - Key achievements:
     * Security Enhancement: Migrated Snowflake authentication from password to private key
     * Log4j migration from 1.x to 2.x (CVE-2021-44228 vulnerability fix)
     * Platform Modernization: Migrated Segments API from .NET to Java with OpenAPI
     * Part of Java 8 to Java 17 upgrade (25% code reduction)
     * Spring Boot 2.x to 3.x migration and code cleanup
     * AWS SDK v1.x to v2.x migration
     * Individual ID to Client-specific MID migration with code cleanup

2. Java/Cloud Developer @ Cognizant (Nov 2019 - May 2021)
   - Cloud-Native Architecture on Microsoft Azure
   - Developed microservices with Spring Boot and Kubernetes
   - Used KITT (Kubernetes In The Trenches) to troubleshoot and monitor Kubernetes clusters
   - Kafka-based event streaming pipelines
   - Microservices design with Spring Batch
   - Agile Scrum teams

3. Big-Data Developer @ Cognizant (May 2018 - Nov 2019)
   - Architected Sqoop-based scripts to process data generated by ETL pipelines migrating 5TB+ data
   - Developed Scala application to load data into HBase and Apache Solr
   - Springboot microservices for querying data from HBase and Solr
   - Served 100+ customer care executives to fetch data from Solr using REST APIs and query the historical data from HBase
   - Tech: Scala, Sqoop, Kafka, HBase, Solr, Spring Boot

4. IoT ‚Äì Java/Big-Data Developer @ TCS (Oct 2015 - May 2018)
   - IoT data ingestion from 100+ devices
   - MQTT broker with Eclipse Mosquitto
   - Real-time streaming with Kafka and Spark
   - Predictive analytics reducing downtime by 35%
   - Dashboard with AngularJS and D3.js

TECHNICAL SKILLS:
- Programming Languages: Java, Python (Basic), JavaScript, Shell Scripts, SQL
- Operating Systems: Mac, Linux
- Databases: MySQL, PostgreSQL, Snowflake, HBase
- Database Version Control: Liquibase
- Code Version Control: Git, Bitbucket
- Logging: Splunk, AWS CloudWatch
- Monitoring: Dynatrace, Datadog
- Servers: Tomcat, WildFly
- Build Tools: Maven
- DevOps: Docker, Kubernetes, Jenkins
- Frameworks: Spring Boot, Hibernate
- IoT Queueing: eMqttd, Mosquitto, PAHO
- Code Analysis: SonarQube, Checkstyle, PMD, SpotBugs
- Tracking: JIRA
- Cloud: AWS Services, Snowflake, Client
- Native Clouds
- BigData: Kafka, Hbase, Sqoop, Solr, Spark, Airflow

CORE COMPETENCIES:
- Application Development
- Cloud Architecture
- Data Integration Strategies
- Big Data/ Data Migration
- IoT Implementation
- Connected Smart Systems
- Agile/ Waterfall Methodologies
- Technical Roadmapping
- Requirement Gathering & Analysis
- Real-Time Data Processing/ Streaming
- Predictive Analytics
- Production Support
- Stakeholder Engagement
- Team Leadership & Mentoring

KEY PROJECTS:

1. Databridge - Enterprise Data Integration Platform
   - Critical component of Dentsu's Merkury - identity solution
   - Responsible for ingestion and publishing process in the application
   - Supported data delivery to different destinations: SFTP, S3, API Endpoint, Snowflake Direct Connect
   - Processes 100GB+ daily with 99.9% accuracy
   - Tech: Snowflake, AWS (SWF, API Gateway, Lambda, S3, SQS, SNS), Python, Airflow, Java 17, Spring Boot 3

2. Retail Cloud Migration
   - Migrated retail systems to cloud with 99.9% uptime
   - Zero-downtime migration with cost optimization
   - Tech: Azure, Java, Spring Batch, MySQL, Liquibase

3. Big Data Migration
   - Migrated MySQL data of 5TB+ to Bigdata platforms
   - Data validation and performance optimization
   - Reduced the time to query large datasets by 60% compared to traditional MySQL set up
   - Application development and maintenance
   - Tech: Hadoop, Sqoop, Solr, Spark, Springboot

4. IoT Analytics Platform
   - Real-time data processing for 10K+ IoT devices
   - Set up analytic pipelines with Kafka, Spark, and HBase
   - Developed a dashboard with AngularJS and D3.js for real-time monitoring
   - Rule engine for alerting and notifications
   - Device Management System (DMSS) for managing IoT devices deployed in the industrial locations
   - Gateways for connecting IoT devices to the platform
   - Predictive analytics and dashboard
   - Tech: Java, Kafka, Cassandra, Spark

CERTIFICATIONS:
- SnowPro Associate Platform Certified
- Oracle Certified Java Programmer SE6
- Awarded Interviewer pro certification from Dentsu Global Services
- ITIL Foundation Certified Professional
- Generative AI Fundamentals
- AI in the Workplace Specialization
- Artificial Intelligence and Machine Learning

ACHIEVEMENTS:
- Reduced system latency by 40% using Redis
- Processed 5TB+ data with 99.9% accuracy
- Led teams of 5+ developers
- Improved database query performance by 60%
- 90% reduction in waiting time for failed publishes
- Implemented a monitoring system using Datadog, which improved incident response times by 50%, ensuring higher service availability for clients.
- Drove trainings for new hires focused on AWS and Snowflake best practices, achieving a 25% reduction in onboarding time and increased team productivity.
- Implemented a 100% automated workflow rerun process through REST API endpoints accessible to the Operations team.
- Spearheaded integration of automated scripts for copying artifacts within S3 in deployment pipelines using Jenkins, reducing deployment times by 20% and minimizing human error during releases.
- Successfully migrated 2 projects to cloud platforms, resulting in a 10% increase in operational efficiency and significant cost reduction.
- Developed automated testing suites that improved application reliability, reducing post-deployment issues by 50%.
- Optimized Apache Solr facets, reducing search time by 30%.
- Introduced in-memory tables instead of querying HBase for Spark processing, reducing processing time by 50% and receiving formal appreciation.

INSTRUCTIONS FOR AI ASSISTANT:
- Be helpful, professional, and conversational
- Provide specific details about Ramji's experience when asked
- If asked about hiring/contact, direct them to the contact form on the website
- If users want detailed professional background or to connect professionally, mention his LinkedIn profile: ${LINKEDIN_PROFILE}
- For networking, endorsements, or professional connections, recommend LinkedIn
- Keep responses concise but informative (200-300 words max)
- Use emojis sparingly for readability
- Be enthusiastic about Ramji's accomplishments
- If you don't know something specific, say so and suggest checking the contact form or LinkedIn profile`;

// Fallback AI function using Hugging Face (free tier)
async function callHuggingFaceAPI(messages) {
  const lastUserMessage = messages[messages.length - 1].content;
  const systemContext = messages[0].content;

  // Combine context and question
  const prompt = `${systemContext.substring(0, 500)}...\n\nQuestion: ${lastUserMessage}\n\nAnswer:`;

  const response = await fetch('https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${HUGGINGFACE_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      inputs: prompt,
      parameters: {
        max_new_tokens: 300,
        temperature: 0.7,
        top_p: 0.9,
        return_full_text: false
      }
    })
  });

  if (!response.ok) {
    throw new Error('Hugging Face API failed');
  }

  const data = await response.json();
  return data[0]?.generated_text || data.generated_text || 'Unable to generate response';
}

export default async function handler(req, res) {
  // Log incoming request
  console.log(`[API] Incoming ${req.method} request from origin:`, req.headers.origin || 'unknown');

  // Enable CORS for all origins
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization, X-Requested-With, Accept, Origin');
  res.setHeader('Access-Control-Max-Age', '86400'); // 24 hours
  res.setHeader('Access-Control-Allow-Credentials', 'true');

  // Handle preflight OPTIONS request
  if (req.method === 'OPTIONS') {
    console.log('[API] ‚úÖ Handling OPTIONS preflight request - CORS headers set');
    return res.status(200).end();
  }

  // Only allow POST requests for actual API calls
  if (req.method !== 'POST') {
    console.log('[API] ‚ùå Method not allowed:', req.method);
    return res.status(405).json({ error: 'Method not allowed. Use POST.' });
  }

  console.log('[API] ‚úÖ Processing POST request');

  try {
    const { message, conversationHistory = [] } = req.body;

    // Validate input
    if (!message || message.trim().length === 0) {
      return res.status(400).json({ error: 'Message is required' });
    }

    // Limit message length
    if (message.length > 500) {
      return res.status(400).json({ error: 'Message too long. Max 500 characters.' });
    }

    // Check if API key is configured
    if (!OPENAI_API_KEY) {
      console.error('OpenAI API key not configured');
      return res.status(500).json({
        error: 'Service temporarily unavailable',
        fallback: true
      });
    }

    // Build conversation messages
    const messages = [
      {
        role: 'system',
        content: SYSTEM_PROMPT
      },
      // Include last 4 messages from history for context
      ...conversationHistory.slice(-4),
      {
        role: 'user',
        content: message.trim()
      }
    ];

    // Try OpenAI first
    let reply;
    let tokensUsed = 0;
    let provider = 'OpenAI';

    try {
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${OPENAI_API_KEY}`
        },
        body: JSON.stringify({
          model: 'gpt-3.5-turbo',
          messages: messages,
          temperature: 0.7,
          max_tokens: 300,
          presence_penalty: 0.6,
          frequency_penalty: 0.3
        })
      });

      if (!response.ok) {
        const errorData = await response.text();
        console.error('OpenAI API error:', response.status, errorData);

        // If rate limited or error, try Hugging Face as fallback
        if (response.status === 429 || response.status >= 500) {
          console.log('[API] üîÑ OpenAI failed, trying Hugging Face fallback...');

          if (HUGGINGFACE_API_KEY) {
            try {
              reply = await callHuggingFaceAPI(messages);
              provider = 'Hugging Face';
              console.log('[API] ‚úÖ Hugging Face fallback successful');
            } catch (hfError) {
              console.error('[API] ‚ùå Hugging Face also failed:', hfError);
              throw new Error(`OpenAI rate limited and Hugging Face failed`);
            }
          } else {
            throw new Error(`OpenAI API error: ${response.statusText}`);
          }
        } else {
          throw new Error(`OpenAI API error: ${response.statusText}`);
        }
      } else {
        const data = await response.json();
        reply = data.choices[0].message.content;
        tokensUsed = data.usage?.total_tokens || 0;
      }
    } catch (openaiError) {
      // If OpenAI completely fails, try Hugging Face
      if (HUGGINGFACE_API_KEY && !reply) {
        console.log('[API] üîÑ OpenAI error, trying Hugging Face fallback...');
        try {
          reply = await callHuggingFaceAPI(messages);
          provider = 'Hugging Face';
          console.log('[API] ‚úÖ Hugging Face fallback successful');
        } catch (hfError) {
          console.error('[API] ‚ùå Both providers failed');
          throw openaiError; // Throw original error
        }
      } else {
        throw openaiError;
      }
    }

    return res.status(200).json({
      reply: reply,
      tokensUsed: tokensUsed,
      provider: provider
    });

  } catch (error) {
    console.error('Chat API Error:', error);

    // Return fallback response
    return res.status(500).json({
      error: 'Failed to generate response',
      message: error.message,
      fallback: true,
      reply: "I'm having trouble connecting right now. Please try again in a moment, or use the contact form below to reach Ramji directly."
    });
  }
}

